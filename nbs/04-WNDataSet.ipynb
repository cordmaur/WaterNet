{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "164ec3ce",
   "metadata": {},
   "source": [
    "WARNING: TESTINGS ARE MISSING FOR THE DATASET CLASS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d003bde1-3fa5-40f3-82c5-500c83f7743c",
   "metadata": {},
   "source": [
    "# WNDataset test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc880c3c",
   "metadata": {},
   "source": [
    "Now that we have one segmentation item (Image + Mask) working, we need something to group N segmentation items and supply them to the learner. Some frameworks separate dataset and dataloader. We will do it in one step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "64bdf6e9-265f-43e4-8d25-8abbbd5d63c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "import rasterio as rio\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from waternet.wndataset import WNDataSet\n",
    "from waternet.wnsegmantationitem import WNSegmentationItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "98d147e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df0bbbb1662480ba86aa6fe33304876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Matching imgs/masks:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WNDataset instance with 11 images\n",
      "Loaded: 0 items\n",
      "Empty: 11 items\n",
      "Loading: 0 items\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dset = WNDataSet.from_masks(\n",
    "    masks_path='d:/temp/22KEV/',\n",
    "    out_shape=(5490, 5490),\n",
    "    patch_size=(512, 512),\n",
    "    step=262,\n",
    "    pattern='*20181*.tif',\n",
    ")\n",
    "\n",
    "print(dset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a0695a",
   "metadata": {},
   "source": [
    "If we try to access one item, without proper initialization..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "fafe2672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bands not set. Set desired bands first.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    dset[0]\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b14caf",
   "metadata": {},
   "source": [
    "We need to specify which bands from the StacImage will be used in the DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "f83be852",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset.bands = ['B11', 'B12']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd1f84d",
   "metadata": {},
   "source": [
    "Now, if we try to access one \"item\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "bf5ec29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image 1 in background\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[0.375 , 0.3749, 0.3972, ..., 0.3526, 0.3675, 0.3712],\n",
       "         [0.3804, 0.3745, 0.3759, ..., 0.3573, 0.3765, 0.3803],\n",
       "         [0.3803, 0.3797, 0.3672, ..., 0.2881, 0.3092, 0.3029],\n",
       "         ...,\n",
       "         [0.3806, 0.3799, 0.3817, ..., 0.3647, 0.3622, 0.356 ],\n",
       "         [0.3816, 0.3777, 0.3817, ..., 0.3665, 0.3665, 0.3627],\n",
       "         [0.3782, 0.3733, 0.3766, ..., 0.3631, 0.3673, 0.3692]],\n",
       " \n",
       "        [[0.2914, 0.2926, 0.3144, ..., 0.2405, 0.257 , 0.2683],\n",
       "         [0.2979, 0.2869, 0.2848, ..., 0.2606, 0.274 , 0.2761],\n",
       "         [0.2938, 0.2858, 0.2714, ..., 0.2277, 0.2452, 0.2478],\n",
       "         ...,\n",
       "         [0.3258, 0.3149, 0.3132, ..., 0.3016, 0.3004, 0.295 ],\n",
       "         [0.3242, 0.3132, 0.3136, ..., 0.3038, 0.3025, 0.2977],\n",
       "         [0.3235, 0.3117, 0.3132, ..., 0.3007, 0.3053, 0.3053]]],\n",
       "       dtype=float32),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8))"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "7c9cef49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WNDataset instance with 11 images\n",
      "Loaded: 1 items\n",
      "Empty: 9 items\n",
      "Loading: 1 items\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "78b847fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Loaded',\n",
       " 1: 'Loading',\n",
       " 2: 'Empty',\n",
       " 3: 'Empty',\n",
       " 4: 'Empty',\n",
       " 5: 'Empty',\n",
       " 6: 'Empty',\n",
       " 7: 'Empty',\n",
       " 8: 'Empty',\n",
       " 9: 'Empty',\n",
       " 10: 'Empty'}"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset.loaded_status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd3ec71",
   "metadata": {},
   "source": [
    "One should note that the length of a DataSet is given by the number of <b>Patches</b> and not the number of \"images\". Each item that we iterate through is a small patch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "5f9e6f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4400\n",
      "(2, 512, 512) (512, 512)\n"
     ]
    }
   ],
   "source": [
    "print(len(dset))\n",
    "print(dset[0][0].shape, dset[0][1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0dc581",
   "metadata": {},
   "source": [
    "Testing a workload..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "5197776f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "150bfaef65694018926362f4edace774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sucessfully\n",
      "Cleared image 0\n",
      "Loading image 2 in background\n",
      "Loaded sucessfully\n",
      "Cleared image 1\n",
      "Loading image 3 in background\n",
      "Loaded sucessfully\n",
      "Cleared image 2\n",
      "Loading image 4 in background\n",
      "Loaded sucessfully\n",
      "Cleared image 3\n",
      "Loading image 5 in background\n",
      "Loaded sucessfully\n",
      "Cleared image 4\n",
      "Loading image 6 in background\n",
      "Loaded sucessfully\n",
      "Cleared image 5\n",
      "Loading image 7 in background\n",
      "Loaded sucessfully\n",
      "Cleared image 6\n",
      "Loading image 8 in background\n",
      "Loaded sucessfully\n",
      "Cleared image 7\n",
      "Loading image 9 in background\n",
      "Loaded sucessfully\n",
      "Cleared image 8\n",
      "Loading image 10 in background\n",
      "Loaded sucessfully\n",
      "Cleared image 9\n",
      "Loading image 0 in background\n",
      "Loaded sucessfully\n"
     ]
    }
   ],
   "source": [
    "for patch, mask in tqdm(dset):\n",
    "    patch.mean()\n",
    "    sleep(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7d25f1",
   "metadata": {},
   "source": [
    "## Putting it into a DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "b32a417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.load import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "2a5b0638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleared image 10\n",
      "Loading image 1 in background\n",
      "torch.Size([2, 512, 512]) torch.Size([512, 512])\n"
     ]
    }
   ],
   "source": [
    "dl = DataLoader(dataset=dset)\n",
    "b = dl.one_batch()\n",
    "print(b[0].shape, b[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "d00db7f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4400"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38608b76",
   "metadata": {},
   "source": [
    "Note that we don't have here the dimension regarding the batch. That's because BatchSize was not specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "b954fbae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "dl = DataLoader(dataset=dset, bs=16)\n",
    "b = dl.one_batch()\n",
    "print(b[0].shape, b[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "5b529e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "275"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "21ad021d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "957052327a1d4d06b471bcf0ffc7d2f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/275 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "Cleared image 0\n",
      "Loading image 2 in background\n",
      "Loaded sucessfully\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "Cleared image 1\n",
      "Loading image 3 in background\n",
      "Loaded sucessfully\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "Cleared image 2\n",
      "Loading image 4 in background\n",
      "Loaded sucessfully\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "Cleared image 3\n",
      "Loading image 5 in background\n",
      "Loaded sucessfully\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "Cleared image 4\n",
      "Loading image 6 in background\n",
      "Loaded sucessfully\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "Cleared image 5\n",
      "Loading image 7 in background\n",
      "Loaded sucessfully\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "Cleared image 6\n",
      "Loading image 8 in background\n",
      "Loaded sucessfully\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "Cleared image 7\n",
      "Loading image 9 in background\n",
      "Loaded sucessfully\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "Cleared image 8\n",
      "Loading image 10 in background\n",
      "Loaded sucessfully\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "Cleared image 9\n",
      "Loading image 0 in background\n",
      "Loaded sucessfully\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n",
      "torch.Size([16, 2, 512, 512]) torch.Size([16, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "for b in tqdm(dl):\n",
    "    print(b[0].shape, b[1].shape)\n",
    "    sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff233ee",
   "metadata": {},
   "source": [
    "After some time I finally understand the do_batch. Looking below, we can see that it creates a batch from a list of items. In our case, it will \"collate\" the items without any further processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "a4491734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleared image 10\n",
      "Loading image 1 in background\n",
      "Loaded sucessfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.3750, 0.3749, 0.3972,  ..., 0.3526, 0.3675, 0.3712],\n",
       "           [0.3804, 0.3745, 0.3759,  ..., 0.3573, 0.3765, 0.3803],\n",
       "           [0.3803, 0.3797, 0.3672,  ..., 0.2881, 0.3092, 0.3029],\n",
       "           ...,\n",
       "           [0.3806, 0.3799, 0.3817,  ..., 0.3647, 0.3622, 0.3560],\n",
       "           [0.3816, 0.3777, 0.3817,  ..., 0.3665, 0.3665, 0.3627],\n",
       "           [0.3782, 0.3733, 0.3766,  ..., 0.3631, 0.3673, 0.3692]],\n",
       " \n",
       "          [[0.2914, 0.2926, 0.3144,  ..., 0.2405, 0.2570, 0.2683],\n",
       "           [0.2979, 0.2869, 0.2848,  ..., 0.2606, 0.2740, 0.2761],\n",
       "           [0.2938, 0.2858, 0.2714,  ..., 0.2277, 0.2452, 0.2478],\n",
       "           ...,\n",
       "           [0.3258, 0.3149, 0.3132,  ..., 0.3016, 0.3004, 0.2950],\n",
       "           [0.3242, 0.3132, 0.3136,  ..., 0.3038, 0.3025, 0.2977],\n",
       "           [0.3235, 0.3117, 0.3132,  ..., 0.3007, 0.3053, 0.3053]]],\n",
       " \n",
       " \n",
       "         [[[0.3411, 0.3001, 0.2992,  ..., 0.2209, 0.2147, 0.2037],\n",
       "           [0.3117, 0.2855, 0.3014,  ..., 0.2377, 0.2461, 0.2085],\n",
       "           [0.2700, 0.2603, 0.2916,  ..., 0.2315, 0.2437, 0.2095],\n",
       "           ...,\n",
       "           [0.0354, 0.0361, 0.0356,  ..., 0.2518, 0.2092, 0.1670],\n",
       "           [0.0375, 0.0355, 0.0356,  ..., 0.2472, 0.1959, 0.1670],\n",
       "           [0.0376, 0.0365, 0.0359,  ..., 0.2407, 0.1847, 0.1530]],\n",
       " \n",
       "          [[0.2381, 0.1817, 0.1683,  ..., 0.1479, 0.1373, 0.1164],\n",
       "           [0.2163, 0.1718, 0.1650,  ..., 0.1538, 0.1710, 0.1298],\n",
       "           [0.1791, 0.1573, 0.1623,  ..., 0.1423, 0.1669, 0.1363],\n",
       "           ...,\n",
       "           [0.0318, 0.0308, 0.0325,  ..., 0.1709, 0.1219, 0.0952],\n",
       "           [0.0319, 0.0314, 0.0328,  ..., 0.1631, 0.1122, 0.0900],\n",
       "           [0.0334, 0.0320, 0.0324,  ..., 0.1522, 0.1035, 0.0803]]]]),\n",
       " tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0]]], dtype=torch.uint8))"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.do_batch([dset[0], dset[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "e03809fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b831ce2",
   "metadata": {},
   "source": [
    "## Creating a validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d03184",
   "metadata": {},
   "source": [
    "To create a learner from Fastai we need to have a Dataloader for the training set and another one for the validation set. To solve that, we will create a new DataSet from another scene, to serve as validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "82169fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WNDataset instance with 1 images\n",
      "Loaded: 0 items\n",
      "Empty: 1 items\n",
      "Loading: 0 items\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segitem = WNSegmentationItem.from_mask(\n",
    "    mask_path='d:/temp/22KEV/S2B_MSIL2A_20210221T133219_R081_T22KEV_watermask.tif',\n",
    "    shape=(5490, 5490),\n",
    "    step=262,\n",
    ")\n",
    "\n",
    "valid_dset = WNDataSet([segitem]) # , segitem])\n",
    "print(valid_dset)\n",
    "len(valid_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "c46e2617",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dset.bands = ['B11', 'B12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "4f40ab49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71aebc68513b464fbc669eb30927ae55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sucessfully\n"
     ]
    }
   ],
   "source": [
    "# test the iteration on the valid_dset\n",
    "\n",
    "for patch, mask in tqdm(valid_dset):\n",
    "    patch.mean()\n",
    "    sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "8c09ba6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Loaded'}"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dset.loaded_status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe282f42",
   "metadata": {},
   "source": [
    "## Creating a Learner from these datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "0d3c400a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "b6f94ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dataloader for the validation dataset\n",
    "valid_dl = DataLoader(valid_dset, bs=16)\n",
    "\n",
    "dls = DataLoaders(dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "49a78789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Dataloaders has 2 dataloaders, and it assigns automatically the training and the validation sets\n",
    "print(len(dls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "f25dc686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WNDataset instance with 1 images\n",
      "Loaded: 1 items\n",
      "Empty: 0 items\n",
      "Loading: 0 items\n",
      " WNDataset instance with 11 images\n",
      "Loaded: 1 items\n",
      "Empty: 10 items\n",
      "Loading: 0 items\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dls.valid_ds, dls.train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "615994bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(pred, targ):\n",
    "    return torch.nn.functional.cross_entropy(pred, targ.squeeze(1).type(torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "8da54fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programs\\miniconda3\\envs\\fastai\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\Programs\\miniconda3\\envs\\fastai\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "learner = unet_learner(dls, arch=resnet18, normalize=False, n_in=2, n_out=3, loss_func=loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "d1246ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "b, targ = dl.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "19dd3c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "29680b48",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at C:\\cb\\pytorch_1000000000000\\work\\c10\\core\\impl\\alloc_cpu.cpp:81] data. DefaultCPUAllocator: not enough memory: you tried to allocate 1644167168 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16300/2709761410.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlearner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\Programs\\miniconda3\\envs\\fastai\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Programs\\miniconda3\\envs\\fastai\\lib\\site-packages\\fastai\\layers.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    406\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m             \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m             \u001b[0mnres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    409\u001b[0m             \u001b[1;31m# We have to remove res.orig to avoid hanging refs and therefore memory leaks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m             \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Programs\\miniconda3\\envs\\fastai\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Programs\\miniconda3\\envs\\fastai\\lib\\site-packages\\fastai\\layers.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    421\u001b[0m     \u001b[1;34m\"Merge a shortcut with the result of the module by adding them or concatenating them if `dense=True`.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[1;31m# %% ../nbs/01_layers.ipynb 118\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at C:\\cb\\pytorch_1000000000000\\work\\c10\\core\\impl\\alloc_cpu.cpp:81] data. DefaultCPUAllocator: not enough memory: you tried to allocate 1644167168 bytes."
     ]
    }
   ],
   "source": [
    "learner.model(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1071390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DynamicUnet(\n",
       "  (layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(2, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (4): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Sequential(\n",
       "      (0): ConvLayer(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (1): ConvLayer(\n",
       "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (4): UnetBlock(\n",
       "      (shuf): PixelShuffle_ICNR(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): PixelShuffle(upscale_factor=2)\n",
       "      )\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): ConvLayer(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (conv2): ConvLayer(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (5): UnetBlock(\n",
       "      (shuf): PixelShuffle_ICNR(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): PixelShuffle(upscale_factor=2)\n",
       "      )\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): ConvLayer(\n",
       "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (conv2): ConvLayer(\n",
       "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (6): UnetBlock(\n",
       "      (shuf): PixelShuffle_ICNR(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): PixelShuffle(upscale_factor=2)\n",
       "      )\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): ConvLayer(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (conv2): ConvLayer(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (7): UnetBlock(\n",
       "      (shuf): PixelShuffle_ICNR(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): PixelShuffle(upscale_factor=2)\n",
       "      )\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): ConvLayer(\n",
       "        (0): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (conv2): ConvLayer(\n",
       "        (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (8): PixelShuffle_ICNR(\n",
       "      (0): ConvLayer(\n",
       "        (0): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (1): PixelShuffle(upscale_factor=2)\n",
       "    )\n",
       "    (9): ResizeToOrig()\n",
       "    (10): MergeLayer()\n",
       "    (11): ResBlock(\n",
       "      (convpath): Sequential(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv2d(98, 98, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): ConvLayer(\n",
       "          (0): Conv2d(98, 98, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (idpath): Sequential()\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): ConvLayer(\n",
       "      (0): Conv2d(98, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (13): fastai.layers.ToTensorBase(tensor_cls=<class 'fastai.torch_core.TensorBase'>)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26af1e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='275' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/275 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 768.00 MiB (GPU 0; 6.00 GiB total capacity; 4.50 GiB already allocated; 0 bytes free; 5.08 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16300/1200345430.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlearner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr_find\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\Programs\\miniconda3\\envs\\fastai\\lib\\site-packages\\fastai\\callback\\schedule.py\u001b[0m in \u001b[0;36mlr_find\u001b[1;34m(self, start_lr, end_lr, num_it, stop_div, show_plot, suggest_funcs)\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[0mn_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m     \u001b[0mcb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLRFinder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_lr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstart_lr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mend_lr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_it\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstop_div\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_logging\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msuggest_funcs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[0mlrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecorder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum_it\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecorder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum_it\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Programs\\miniconda3\\envs\\fastai\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, n_epoch, lr, wd, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[0;32m    254\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_hypers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_fit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCancelFitException\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_end_cleanup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_end_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Programs\\miniconda3\\envs\\fastai\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[1;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'before_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'after_cancel_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'after_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Programs\\miniconda3\\envs\\fastai\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36m_do_fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    243\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'epoch'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Programs\\miniconda3\\envs\\fastai\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[1;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'before_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'after_cancel_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'after_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Programs\\miniconda3\\envs\\fastai\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36m_do_epoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_do_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_epoch_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Programs\\miniconda3\\envs\\fastai\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36m_do_epoch_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_do_epoch_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mds_idx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Programs\\miniconda3\\envs\\fastai\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[1;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'before_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'after_cancel_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'after_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Programs\\miniconda3\\envs\\fastai\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_grad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Programs\\miniconda3\\envs\\fastai\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36mone_batch\u001b[1;34m(self, i, b)\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_one_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'batch'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCancelBatchException\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Programs\\miniconda3\\envs\\fastai\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[1;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'before_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'after_cancel_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'after_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Programs\\miniconda3\\envs\\fastai\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36m_do_one_batch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_do_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'after_pred'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Programs\\miniconda3\\envs\\fastai\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Programs\\miniconda3\\envs\\fastai\\lib\\site-packages\\fastai\\layers.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    406\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m             \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m             \u001b[0mnres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    409\u001b[0m             \u001b[1;31m# We have to remove res.orig to avoid hanging refs and therefore memory leaks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m             \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Programs\\miniconda3\\envs\\fastai\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Programs\\miniconda3\\envs\\fastai\\lib\\site-packages\\fastai\\vision\\models\\unet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, up_in)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mssh\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mup_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[0mup_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mup_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'nearest'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mcat_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mup_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcat_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 768.00 MiB (GPU 0; 6.00 GiB total capacity; 4.50 GiB already allocated; 0 bytes free; 5.08 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92c3e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b611d61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyIterator:\n",
    "    def __iter__(self):\n",
    "        yield from range(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789a422a",
   "metadata": {},
   "outputs": [],
   "source": [
    "di = DummyIterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198aa17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(di))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d43863e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0.375 , 0.3749, 0.3972, ..., 0.3526, 0.3675, 0.3712],\n",
       "         [0.3804, 0.3745, 0.3759, ..., 0.3573, 0.3765, 0.3803],\n",
       "         [0.3803, 0.3797, 0.3672, ..., 0.2881, 0.3092, 0.3029],\n",
       "         ...,\n",
       "         [0.3806, 0.3799, 0.3817, ..., 0.3647, 0.3622, 0.356 ],\n",
       "         [0.3816, 0.3777, 0.3817, ..., 0.3665, 0.3665, 0.3627],\n",
       "         [0.3782, 0.3733, 0.3766, ..., 0.3631, 0.3673, 0.3692]],\n",
       " \n",
       "        [[0.2914, 0.2926, 0.3144, ..., 0.2405, 0.257 , 0.2683],\n",
       "         [0.2979, 0.2869, 0.2848, ..., 0.2606, 0.274 , 0.2761],\n",
       "         [0.2938, 0.2858, 0.2714, ..., 0.2277, 0.2452, 0.2478],\n",
       "         ...,\n",
       "         [0.3258, 0.3149, 0.3132, ..., 0.3016, 0.3004, 0.295 ],\n",
       "         [0.3242, 0.3132, 0.3136, ..., 0.3038, 0.3025, 0.2977],\n",
       "         [0.3235, 0.3117, 0.3132, ..., 0.3007, 0.3053, 0.3053]]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d256f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbb7d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from waternet.wnstacimage import WNStacImage\n",
    "import planetary_computer as pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a313fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = WNStacImage.from_tile(\n",
    "    tile='22KEV',\n",
    "    str_date=\"2022-08-25\",\n",
    "    shape=(5490, 5490)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f7163f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Asset href=https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/22/K/EV/2022/08/25/S2B_MSIL2A_20220825T133149_N0400_R081_T22KEV_20220826T055538.SAFE/GRANULE/L2A_T22KEV_A028564_20220825T133432/IMG_DATA/R60m/T22KEV_20220825T133149_B01_60m.tif>]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img['B01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e7b081",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = rio.open(pc.sign(img['B01'][0].href), dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330fb5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m\n",
      "\u001b[0mrio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdriver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mnodata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0msharing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m\n",
      "Open a dataset for reading or writing.\n",
      "\n",
      "The dataset may be located in a local file, in a resource located by\n",
      "a URL, or contained within a stream of bytes.\n",
      "\n",
      "In read ('r') or read/write ('r+') mode, no keyword arguments are\n",
      "required: these attributes are supplied by the opened dataset.\n",
      "\n",
      "In write ('w' or 'w+') mode, the driver, width, height, count, and dtype\n",
      "keywords are strictly required.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "fp : str, file object or pathlib.Path object\n",
      "    A filename or URL, a file object opened in binary ('rb') mode,\n",
      "    or a Path object.\n",
      "mode : str, optional\n",
      "    'r' (read, the default), 'r+' (read/write), 'w' (write), or\n",
      "    'w+' (write/read).\n",
      "driver : str, optional\n",
      "    A short format driver name (e.g. \"GTiff\" or \"JPEG\") or a list of\n",
      "    such names (see GDAL docs at\n",
      "    http://www.gdal.org/formats_list.html). In 'w' or 'w+' modes\n",
      "    a single name is required. In 'r' or 'r+' modes the driver can\n",
      "    usually be omitted. Registered drivers will be tried\n",
      "    sequentially until a match is found. When multiple drivers are\n",
      "    available for a format such as JPEG2000, one of them can be\n",
      "    selected by using this keyword argument.\n",
      "width : int, optional\n",
      "    The number of columns of the raster dataset. Required in 'w' or\n",
      "    'w+' modes, it is ignored in 'r' or 'r+' modes.\n",
      "height : int, optional\n",
      "    The number of rows of the raster dataset. Required in 'w' or\n",
      "    'w+' modes, it is ignored in 'r' or 'r+' modes.\n",
      "count : int, optional\n",
      "    The count of dataset bands. Required in 'w' or 'w+' modes, it is\n",
      "    ignored in 'r' or 'r+' modes.\n",
      "crs : str, dict, or CRS; optional\n",
      "    The coordinate reference system. Required in 'w' or 'w+' modes,\n",
      "    it is ignored in 'r' or 'r+' modes.\n",
      "transform : Affine instance, optional\n",
      "    Affine transformation mapping the pixel space to geographic\n",
      "    space. Required in 'w' or 'w+' modes, it is ignored in 'r' or\n",
      "    'r+' modes.\n",
      "dtype : str or numpy dtype\n",
      "    The data type for bands. For example: 'uint8' or\n",
      "    ``rasterio.uint16``. Required in 'w' or 'w+' modes, it is\n",
      "    ignored in 'r' or 'r+' modes.\n",
      "nodata : int, float, or nan; optional\n",
      "    Defines the pixel value to be interpreted as not valid data.\n",
      "    Required in 'w' or 'w+' modes, it is ignored in 'r' or 'r+'\n",
      "    modes.\n",
      "sharing : bool; optional\n",
      "    To reduce overhead and prevent programs from running out of file\n",
      "    descriptors, rasterio maintains a pool of shared low level\n",
      "    dataset handles. When `True` this function will use a shared\n",
      "    handle if one is available. Multithreaded programs must avoid\n",
      "    sharing and should set *sharing* to `False`.\n",
      "kwargs : optional\n",
      "    These are passed to format drivers as directives for creating or\n",
      "    interpreting datasets. For example: in 'w' or 'w+' modes\n",
      "    a `tiled=True` keyword argument will direct the GeoTIFF format\n",
      "    driver to create a tiled, rather than striped, TIFF.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "A ``DatasetReader`` or ``DatasetWriter`` object.\n",
      "\n",
      "Examples\n",
      "--------\n",
      "\n",
      "To open a GeoTIFF for reading using standard driver discovery and\n",
      "no directives:\n",
      "\n",
      ">>> import rasterio\n",
      ">>> with rasterio.open('example.tif') as dataset:\n",
      "...     print(dataset.profile)\n",
      "\n",
      "To open a JPEG2000 using only the JP2OpenJPEG driver:\n",
      "\n",
      ">>> with rasterio.open(\n",
      "...         'example.jp2', driver='JP2OpenJPEG') as dataset:\n",
      "...     print(dataset.profile)\n",
      "\n",
      "To create a new 8-band, 16-bit unsigned, tiled, and LZW-compressed\n",
      "GeoTIFF with a global extent and 0.5 degree resolution:\n",
      "\n",
      ">>> from rasterio.transform import from_origin\n",
      ">>> with rasterio.open(\n",
      "...         'example.tif', 'w', driver='GTiff', dtype='uint16',\n",
      "...         width=720, height=360, count=8, crs='EPSG:4326',\n",
      "...         transform=from_origin(-180.0, 90.0, 0.5, 0.5),\n",
      "...         nodata=0, tiled=True, compress='lzw') as dataset:\n",
      "...     dataset.write(...)\n",
      "\u001b[1;31mFile:\u001b[0m      d:\\programs\\miniconda3\\envs\\fastai\\lib\\site-packages\\rasterio\\__init__.py\n",
      "\u001b[1;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "rio.open?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9d1d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ds.read().astype('float32')/20000).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9a0f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \"mask_path\": \"d:/temp/22KEV/S2A_MSIL2A_20180123T133221_R081_T22KEV_watermask.tif\",\n",
    "        \"stac_tile\": \"22KEV\",\n",
    "        \"stac_date\": \"2022-08-25\",\n",
    "        \"stac_name\": \"S2B_MSIL2A_20220825T133149_R081_T22KEV_20220826T055538\",\n",
    "        \"stac_shape\": (5490, 5490),\n",
    "        \"stac_bands\": [\"B01\", \"B09\"],\n",
    "    }\n",
    "    return fixtures\n",
    "\n",
    "\n",
    "@pytest.fixture(scope=\"session\")\n",
    "def stac_img(test_data):\n",
    "    \"\"\"Load a stac_img that will be used accross multiple tests.\"\"\"\n",
    "\n",
    "    stac_img = WNStacImage.from_tile(\n",
    "        tile=test_data[\"stac_tile\"],\n",
    "        str_date=test_data[\"stac_date\"],\n",
    "        shape=test_data[\"stac_shape\"],\n",
    "    )\n",
    "\n",
    "    assert stac_img.shape == test_data[\"stac_shape\"]\n",
    "    assert stac_img.name == test_data[\"stac_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a6449a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m\n",
      "\u001b[0mrio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdriver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mnodata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0msharing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m\n",
      "Open a dataset for reading or writing.\n",
      "\n",
      "The dataset may be located in a local file, in a resource located by\n",
      "a URL, or contained within a stream of bytes.\n",
      "\n",
      "In read ('r') or read/write ('r+') mode, no keyword arguments are\n",
      "required: these attributes are supplied by the opened dataset.\n",
      "\n",
      "In write ('w' or 'w+') mode, the driver, width, height, count, and dtype\n",
      "keywords are strictly required.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "fp : str, file object or pathlib.Path object\n",
      "    A filename or URL, a file object opened in binary ('rb') mode,\n",
      "    or a Path object.\n",
      "mode : str, optional\n",
      "    'r' (read, the default), 'r+' (read/write), 'w' (write), or\n",
      "    'w+' (write/read).\n",
      "driver : str, optional\n",
      "    A short format driver name (e.g. \"GTiff\" or \"JPEG\") or a list of\n",
      "    such names (see GDAL docs at\n",
      "    http://www.gdal.org/formats_list.html). In 'w' or 'w+' modes\n",
      "    a single name is required. In 'r' or 'r+' modes the driver can\n",
      "    usually be omitted. Registered drivers will be tried\n",
      "    sequentially until a match is found. When multiple drivers are\n",
      "    available for a format such as JPEG2000, one of them can be\n",
      "    selected by using this keyword argument.\n",
      "width : int, optional\n",
      "    The number of columns of the raster dataset. Required in 'w' or\n",
      "    'w+' modes, it is ignored in 'r' or 'r+' modes.\n",
      "height : int, optional\n",
      "    The number of rows of the raster dataset. Required in 'w' or\n",
      "    'w+' modes, it is ignored in 'r' or 'r+' modes.\n",
      "count : int, optional\n",
      "    The count of dataset bands. Required in 'w' or 'w+' modes, it is\n",
      "    ignored in 'r' or 'r+' modes.\n",
      "crs : str, dict, or CRS; optional\n",
      "    The coordinate reference system. Required in 'w' or 'w+' modes,\n",
      "    it is ignored in 'r' or 'r+' modes.\n",
      "transform : Affine instance, optional\n",
      "    Affine transformation mapping the pixel space to geographic\n",
      "    space. Required in 'w' or 'w+' modes, it is ignored in 'r' or\n",
      "    'r+' modes.\n",
      "dtype : str or numpy dtype\n",
      "    The data type for bands. For example: 'uint8' or\n",
      "    ``rasterio.uint16``. Required in 'w' or 'w+' modes, it is\n",
      "    ignored in 'r' or 'r+' modes.\n",
      "nodata : int, float, or nan; optional\n",
      "    Defines the pixel value to be interpreted as not valid data.\n",
      "    Required in 'w' or 'w+' modes, it is ignored in 'r' or 'r+'\n",
      "    modes.\n",
      "sharing : bool; optional\n",
      "    To reduce overhead and prevent programs from running out of file\n",
      "    descriptors, rasterio maintains a pool of shared low level\n",
      "    dataset handles. When `True` this function will use a shared\n",
      "    handle if one is available. Multithreaded programs must avoid\n",
      "    sharing and should set *sharing* to `False`.\n",
      "kwargs : optional\n",
      "    These are passed to format drivers as directives for creating or\n",
      "    interpreting datasets. For example: in 'w' or 'w+' modes\n",
      "    a `tiled=True` keyword argument will direct the GeoTIFF format\n",
      "    driver to create a tiled, rather than striped, TIFF.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "A ``DatasetReader`` or ``DatasetWriter`` object.\n",
      "\n",
      "Examples\n",
      "--------\n",
      "\n",
      "To open a GeoTIFF for reading using standard driver discovery and\n",
      "no directives:\n",
      "\n",
      ">>> import rasterio\n",
      ">>> with rasterio.open('example.tif') as dataset:\n",
      "...     print(dataset.profile)\n",
      "\n",
      "To open a JPEG2000 using only the JP2OpenJPEG driver:\n",
      "\n",
      ">>> with rasterio.open(\n",
      "...         'example.jp2', driver='JP2OpenJPEG') as dataset:\n",
      "...     print(dataset.profile)\n",
      "\n",
      "To create a new 8-band, 16-bit unsigned, tiled, and LZW-compressed\n",
      "GeoTIFF with a global extent and 0.5 degree resolution:\n",
      "\n",
      ">>> from rasterio.transform import from_origin\n",
      ">>> with rasterio.open(\n",
      "...         'example.tif', 'w', driver='GTiff', dtype='uint16',\n",
      "...         width=720, height=360, count=8, crs='EPSG:4326',\n",
      "...         transform=from_origin(-180.0, 90.0, 0.5, 0.5),\n",
      "...         nodata=0, tiled=True, compress='lzw') as dataset:\n",
      "...     dataset.write(...)\n",
      "\u001b[1;31mFile:\u001b[0m      d:\\programs\\miniconda3\\envs\\fastai\\lib\\site-packages\\rasterio\\__init__.py\n",
      "\u001b[1;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "rio.open?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad29f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b8d564a5e78fa920f6d109e3b6389da476a9ea846c62606ff1aca0006ea12436"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
